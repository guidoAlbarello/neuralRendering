from sklearn.neural_network import MLPRegressor
import formatter
from PIL import Image
from numpy import asarray
import itertools

def showPlot(array):
    i = 0
    for e in array:
        if i % 100 == 0:
            print(e)
        else:
            print(e, end='')
        i += 1


def loadImage():
    image = Image.open('densityMap.png')
    data = asarray(image)
    print(type(data))
    print(data.shape)

    X = []
    y = []
    height = len(data)
    width = len(data[0])

    for row in range(len(data)):
        for col in range(len(data[row])):
            X.append([col/float(width), row/float(height)])
            y.append(1 if data[row][col][0] != 0 else 0)
    return X, y


def makeQuad():
    Y = []
    X = []
    rows = 100
    cols = 100
    for i in range(rows):
        for j in range(cols):
            X.append([j/cols, i/rows])
            if i >= 50 and i < 90 and j > 30 and j < 60:
                Y.append(0)
            else:
                Y.append(1)
    return X, Y

def makeCircle():
    Y = []
    X = []
    rows = 100
    cols = 100
    for x, y in itertools.product(range(rows), range(cols)):
        coordX = x/cols
        coordY = y/rows
        X.append([coordX, coordY])
        ecuacion = (coordX-0.5)**2 + (coordY-0.5)**2
        if ecuacion <= 0.25**2:
            Y.append(1)
        else:
            Y.append(0)
    return X, Y


#X, y = makeCircle()
X = [[0.0, 0.0], [0.08333333333333333, 0.0], [0.16666666666666666, 0.0], [0.25, 0.0], [0.3333333333333333, 0.0], [0.4166666666666667, 0.0], [0.5, 0.0], [0.5833333333333334, 0.0], [0.6666666666666666, 0.0], [0.75, 0.0], [0.8333333333333334, 0.0], [0.9166666666666666, 0.0], [0.0, 0.08333333333333333], [0.08333333333333333, 0.08333333333333333], [0.16666666666666666, 0.08333333333333333], [0.25, 0.08333333333333333], [0.3333333333333333, 0.08333333333333333], [0.4166666666666667, 0.08333333333333333], [0.5, 0.08333333333333333], [0.5833333333333334, 0.08333333333333333], [0.6666666666666666, 0.08333333333333333], [0.75, 0.08333333333333333], [0.8333333333333334, 0.08333333333333333], [0.9166666666666666, 0.08333333333333333], [0.0, 0.16666666666666666], [0.08333333333333333, 0.16666666666666666], [0.16666666666666666, 0.16666666666666666], [0.25, 0.16666666666666666], [0.3333333333333333, 0.16666666666666666], [0.4166666666666667, 0.16666666666666666], [0.5, 0.16666666666666666], [0.5833333333333334, 0.16666666666666666], [0.6666666666666666, 0.16666666666666666], [0.75, 0.16666666666666666], [0.8333333333333334, 0.16666666666666666], [0.9166666666666666, 0.16666666666666666], [0.0, 0.25], [0.08333333333333333, 0.25], [0.16666666666666666, 0.25], [0.25, 0.25], [0.3333333333333333, 0.25], [0.4166666666666667, 0.25], [0.5, 0.25], [0.5833333333333334, 0.25], [0.6666666666666666, 0.25], [0.75, 0.25], [0.8333333333333334, 0.25], [0.9166666666666666, 0.25], [0.0, 0.3333333333333333], [0.08333333333333333, 0.3333333333333333], [0.16666666666666666, 0.3333333333333333], [0.25, 0.3333333333333333], [0.3333333333333333, 0.3333333333333333], [0.4166666666666667, 0.3333333333333333], [0.5, 0.3333333333333333], [0.5833333333333334, 0.3333333333333333], [0.6666666666666666, 0.3333333333333333], [0.75, 0.3333333333333333], [0.8333333333333334, 0.3333333333333333], [0.9166666666666666, 0.3333333333333333], [0.0, 0.4166666666666667], [0.08333333333333333, 0.4166666666666667], [0.16666666666666666, 0.4166666666666667], [0.25, 0.4166666666666667], [0.3333333333333333, 0.4166666666666667], [0.4166666666666667, 0.4166666666666667], [0.5, 0.4166666666666667], [0.5833333333333334, 0.4166666666666667], [0.6666666666666666, 0.4166666666666667], [0.75, 0.4166666666666667], [0.8333333333333334, 0.4166666666666667], [0.9166666666666666, 0.4166666666666667], [0.0, 0.5], [0.08333333333333333, 0.5], [0.16666666666666666, 0.5], [0.25, 0.5], [0.3333333333333333, 0.5], [0.4166666666666667, 0.5], [0.5, 0.5], [0.5833333333333334, 0.5], [0.6666666666666666, 0.5], [0.75, 0.5], [0.8333333333333334, 0.5], [0.9166666666666666, 0.5], [0.0, 0.5833333333333334], [0.08333333333333333, 0.5833333333333334], [0.16666666666666666, 0.5833333333333334], [0.25, 0.5833333333333334], [0.3333333333333333, 0.5833333333333334], [0.4166666666666667, 0.5833333333333334], [0.5, 0.5833333333333334], [0.5833333333333334, 0.5833333333333334], [0.6666666666666666, 0.5833333333333334], [0.75, 0.5833333333333334], [0.8333333333333334, 0.5833333333333334], [0.9166666666666666, 0.5833333333333334], [0.0, 0.6666666666666666], [0.08333333333333333, 0.6666666666666666], [0.16666666666666666, 0.6666666666666666], [0.25, 0.6666666666666666], [0.3333333333333333, 0.6666666666666666], [0.4166666666666667, 0.6666666666666666], [0.5, 0.6666666666666666], [0.5833333333333334, 0.6666666666666666], [0.6666666666666666, 0.6666666666666666], [0.75, 0.6666666666666666], [0.8333333333333334, 0.6666666666666666], [0.9166666666666666, 0.6666666666666666], [0.0, 0.75], [0.08333333333333333, 0.75], [0.16666666666666666, 0.75], [0.25, 0.75], [0.3333333333333333, 0.75], [0.4166666666666667, 0.75], [0.5, 0.75], [0.5833333333333334, 0.75], [0.6666666666666666, 0.75], [0.75, 0.75], [0.8333333333333334, 0.75], [0.9166666666666666, 0.75], [0.0, 0.8333333333333334], [0.08333333333333333, 0.8333333333333334], [0.16666666666666666, 0.8333333333333334], [0.25, 0.8333333333333334], [0.3333333333333333, 0.8333333333333334], [0.4166666666666667, 0.8333333333333334], [0.5, 0.8333333333333334], [0.5833333333333334, 0.8333333333333334], [0.6666666666666666, 0.8333333333333334], [0.75, 0.8333333333333334], [0.8333333333333334, 0.8333333333333334], [0.9166666666666666, 0.8333333333333334], [0.0, 0.9166666666666666], [0.08333333333333333, 0.9166666666666666], [0.16666666666666666, 0.9166666666666666], [0.25, 0.9166666666666666], [0.3333333333333333, 0.9166666666666666], [0.4166666666666667, 0.9166666666666666], [0.5, 0.9166666666666666], [0.5833333333333334, 0.9166666666666666], [0.6666666666666666, 0.9166666666666666], [0.75, 0.9166666666666666], [0.8333333333333334, 0.9166666666666666], [0.9166666666666666, 0.9166666666666666]]
y = [4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 4, 3, 2, 2, 2, 1, 1, 1, 2, 2, 2, 3, 3, 3, 2, 1, 1, 1, 0, 1, 1, 1, 2, 3, 3, 2, 2, 1, 0, 0, 0, 0, 0, 1, 2, 2, 3, 2, 1, 1, 0, -1, -1, -1, 0, 1, 1, 2, 3, 2, 1, 0, 0, -1, -2, -1, 0, 0, 1, 2, 3, 2, 1, 1, 0, -1, -1, -1, 0, 1, 1, 2, 3, 2, 2, 1, 0, 0, 0, 0, 0, 1, 2, 2, 3, 3, 2, 1, 1, 1, 0, 1, 1, 1, 2, 3, 4, 3, 2, 2, 2, 1, 1, 1, 2, 2, 2, 3, 4, 3, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3]

clf = MLPRegressor(solver='lbfgs', alpha=1e-5, activation='relu',
                    hidden_layer_sizes=(16,16 ,8), random_state=1, max_iter=200, verbose=True)
clf.fit(X, y)
print(clf.predict([[0.5,0.5]]))
formatter.toTestShader(formatter.SquashFunction.RELU,
                       clf.coefs_, clf.intercepts_, './net.glsl')